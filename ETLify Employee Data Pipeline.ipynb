{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36b3e0d-0c08-4957-9b9b-31040ed98c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60797ae1-4926-40f8-9ab2-847a2674f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='retail_etl.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d39a01f9-deb8-4915-a044-dcb6a37195b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ 'data/' folder already exists.\n"
     ]
    }
   ],
   "source": [
    "# Create the 'data/' folder if it doesn't exist\n",
    "data_folder = 'data/'\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "    print(\"‚úÖ 'data/' folder created. Please add CSVs inside it.\")\n",
    "else:\n",
    "    print(\"üìÅ 'data/' folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e5bbb6-a2bd-4811-823f-514b55bd0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ 'data/' folder already exists.\n",
      "‚úÖ Raw data combined:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define folder where CSVs are stored\n",
    "data_folder = 'data/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "    print(\"‚úÖ 'data/' folder created. Add your CSV files into this folder.\")\n",
    "else:\n",
    "    print(\"üìÅ 'data/' folder already exists.\")\n",
    "\n",
    "# Combine all CSV files in the folder into a single DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(data_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"‚úÖ Raw data combined:\")\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab8eed70-47d7-440e-9518-f8eae5c01988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Available columns after normalization:\n",
      "[]\n",
      "‚ùå Missing columns in the data: ['quantity_sold', 'unit_price', 'discount_percent', 'payment_mode', 'date', 'store_id', 'product_id', 'product_name']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# ‚úÖ Normalize column names FIRST\n",
    "combined_df.columns = [col.strip().lower().replace(' ', '_') for col in combined_df.columns]\n",
    "\n",
    "# üîç Step 1: Print available columns\n",
    "print(\"üìã Available columns after normalization:\")\n",
    "print(combined_df.columns.tolist())\n",
    "\n",
    "# ‚úÖ Step 2: Check if required columns exist before proceeding\n",
    "required_columns = ['quantity_sold', 'unit_price', 'discount_percent', 'payment_mode', 'date', 'store_id', 'product_id', 'product_name']\n",
    "\n",
    "missing_columns = [col for col in required_columns if col not in combined_df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"‚ùå Missing columns in the data: {missing_columns}\")\n",
    "else:\n",
    "    # ‚úÖ Handle missing values\n",
    "    combined_df.fillna({\n",
    "        'quantity_sold': 0,\n",
    "        'unit_price': 0.0,\n",
    "        'discount_percent': 0.0,\n",
    "        'payment_mode': 'Unknown'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # ‚úÖ Calculate total sale value\n",
    "    combined_df['total_sale_value'] = (\n",
    "        combined_df['quantity_sold'] *\n",
    "        combined_df['unit_price'] *\n",
    "        (1 - combined_df['discount_percent'] / 100)\n",
    "    )\n",
    "\n",
    "    # ‚úÖ Convert 'date' column to datetime\n",
    "    combined_df['date'] = pd.to_datetime(combined_df['date'], errors='coerce')\n",
    "\n",
    "    # ‚úÖ Drop duplicates\n",
    "    combined_df.drop_duplicates(subset=['store_id', 'date', 'product_id'], inplace=True)\n",
    "\n",
    "    # ‚úÖ Categorize sales\n",
    "    combined_df['sale_category'] = np.where(\n",
    "        combined_df['total_sale_value'] >= 10000, 'High',\n",
    "        np.where(combined_df['total_sale_value'] >= 5000, 'Medium', 'Low')\n",
    "    )\n",
    "\n",
    "    # üëÄ Preview the cleaned data\n",
    "    print(\"‚úÖ Transformed DataFrame:\")\n",
    "    print(combined_df.head())\n",
    "    print(combined_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cca3051-5023-41e8-9d20-26286ec5ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå MySQL Error: 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "try:\n",
    "    # ‚úÖ Connect to MySQL database (update credentials if needed)\n",
    "    mydb = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"root\",      # Update if you use a different password\n",
    "        database=\"retail\"     # Make sure this DB exists. Create manually if needed.\n",
    "    )\n",
    "\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    # ‚úÖ Create table if not exists\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS retail_sales (\n",
    "            store_id VARCHAR(20),\n",
    "            date DATE,\n",
    "            product_id VARCHAR(20),\n",
    "            product_name VARCHAR(100),\n",
    "            quantity_sold INT,\n",
    "            unit_price FLOAT,\n",
    "            discount_percent FLOAT,\n",
    "            payment_mode VARCHAR(20),\n",
    "            total_sale_value FLOAT,\n",
    "            sale_category VARCHAR(20),\n",
    "            PRIMARY KEY (store_id, date, product_id)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # ‚úÖ Insert each row with ON DUPLICATE KEY UPDATE (idempotent insert)\n",
    "    for _, row in combined_df.iterrows():\n",
    "        sql = \"\"\"\n",
    "            INSERT INTO retail_sales (\n",
    "                store_id, date, product_id, product_name,\n",
    "                quantity_sold, unit_price, discount_percent,\n",
    "                payment_mode, total_sale_value, sale_category\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON DUPLICATE KEY UPDATE\n",
    "                quantity_sold=VALUES(quantity_sold),\n",
    "                unit_price=VALUES(unit_price),\n",
    "                discount_percent=VALUES(discount_percent),\n",
    "                payment_mode=VALUES(payment_mode),\n",
    "                total_sale_value=VALUES(total_sale_value),\n",
    "                sale_category=VALUES(sale_category)\n",
    "        \"\"\"\n",
    "        values = (\n",
    "            row['store_id'],\n",
    "            row['date'],\n",
    "            row['product_id'],\n",
    "            row['product_name'],\n",
    "            int(row['quantity_sold']),\n",
    "            float(row['unit_price']),\n",
    "            float(row['discount_percent']),\n",
    "            row['payment_mode'],\n",
    "            float(row['total_sale_value']),\n",
    "            row['sale_category']\n",
    "        )\n",
    "        cursor.execute(sql, values)\n",
    "\n",
    "    # ‚úÖ Commit and close\n",
    "    mydb.commit()\n",
    "    cursor.close()\n",
    "    mydb.close()\n",
    "\n",
    "    print(\"‚úÖ Data loaded into MySQL successfully.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"‚ùå MySQL Error:\", err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "608d1c10-231d-47d4-afc7-6c163712b54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Available columns: []\n",
      "‚ùå Missing required column(s): ['store_id', 'product_name', 'total_sale_value', 'date']\n"
     ]
    }
   ],
   "source": [
    "# üîç Check actual column names first\n",
    "print(\"üìã Available columns:\", combined_df.columns.tolist())\n",
    "\n",
    "# Map fallback names if store_id is missing\n",
    "fallbacks = {\n",
    "    'store_id': None,\n",
    "    'product_name': None,\n",
    "    'total_sale_value': None,\n",
    "    'date': None\n",
    "}\n",
    "\n",
    "# Try to detect correct column names dynamically\n",
    "for col in combined_df.columns:\n",
    "    if 'store' in col and 'id' in col:\n",
    "        fallbacks['store_id'] = col\n",
    "    if 'product' in col and 'name' in col:\n",
    "        fallbacks['product_name'] = col\n",
    "    if 'total_sale_value' in col:\n",
    "        fallbacks['total_sale_value'] = col\n",
    "    if col == 'date':\n",
    "        fallbacks['date'] = col\n",
    "\n",
    "# Validate all required columns found\n",
    "if None in fallbacks.values():\n",
    "    print(\"‚ùå Missing required column(s):\", [k for k, v in fallbacks.items() if v is None])\n",
    "else:\n",
    "    # ‚úÖ Total sales per store\n",
    "    store_sales = (\n",
    "        combined_df.groupby(fallbacks['store_id'])[fallbacks['total_sale_value']]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(by=fallbacks['total_sale_value'], ascending=False)\n",
    "    )\n",
    "    store_sales.to_csv('store_sales_summary.csv', index=False)\n",
    "    print(\"‚úÖ store_sales_summary.csv created.\")\n",
    "\n",
    "    # ‚úÖ Top 5 products\n",
    "    top_products = (\n",
    "        combined_df.groupby(fallbacks['product_name'])[fallbacks['total_sale_value']]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(5)\n",
    "        .reset_index()\n",
    "    )\n",
    "    top_products.to_csv('top_products.csv', index=False)\n",
    "    print(\"‚úÖ top_products.csv created.\")\n",
    "\n",
    "    # ‚úÖ Daily sales trend\n",
    "    daily_trend = (\n",
    "        combined_df.groupby([fallbacks['date'], fallbacks['store_id']])[fallbacks['total_sale_value']]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(by=fallbacks['date'])\n",
    "    )\n",
    "    daily_trend.to_csv('daily_sales_trend.csv', index=False)\n",
    "    print(\"‚úÖ daily_sales_trend.csv created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8408c-3c47-4405-b470-e224ea5775be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
